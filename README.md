# ğŸš€ **Dynamic Pricing Using Reinforcement Learning for Blinkit**  

ğŸ“Œ **Author:** Jasraj Shendge  
ğŸ“Œ **Institution:** Manipal University Jaipur  

## ğŸ“– **Introduction**  

### **Problem Statement**  
Blinkit, a fast-growing **online grocery delivery platform**, faces challenges in **optimizing pricing strategies** to maximize revenue, sales, and customer satisfaction. Unlike static pricing, **dynamic pricing** adapts based on real-time demand, seasonality, and competition.  

### **Business Goals**  
âœ… **Identify the optimal pricing strategy** to maximize revenue and profit.  
âœ… **Understand price elasticity** and how customers respond to pricing changes.  
âœ… **Implement dynamic pricing** that adjusts in **real-time**.  

---

## ğŸ¯ **Project Contributions**  

âœ”ï¸ **Incorporating Price Elasticity of Demand (PED) for Smarter Pricing**  
âœ”ï¸ **Developing a Reinforcement Learning (RL) Model for Dynamic Pricing**  
âœ”ï¸ **Visualizing & Evaluating Revenue, Profitability, and PED Alignment**  

---

## ğŸ“Š **Dataset Description & Visualization**  

The dataset contains essential pricing and sales data:  

| **Column Name**      | **Description**  |
|----------------------|----------------|
| `Item_Identifier`    | Unique product ID |
| `Item_Type`         | Product category |
| `Item_MRP`          | Maximum Retail Price |
| `Item_Outlet_Sales` | Total sales generated |
| `Outlet_Location_Type` | Store location type (Urban/Rural) |
| `Outlet_Type`       | Type of store |

### ğŸ“Œ **Data Insights**  
- ğŸ“‰ **Price vs. Sales Relationship:** Scatter plot showing sales variation with price changes.  
- ğŸ“Š **Distribution of Price Elasticity of Demand (PED):** Identifies elastic & inelastic products.  

---

## ğŸ§  **Algorithm Used: Q-Learning for Dynamic Pricing**  

Q-learning is a **reinforcement learning algorithm** that helps the agent learn **optimal pricing strategies** by interacting with the environment.  

### ğŸ”¢ **Q-Learning Formula**  

\[
Q(s, a) \leftarrow Q(s, a) + \alpha \left[ r + \gamma \max Q(s', a') - Q(s, a) \right]
\]

Where:  
- \( Q(s, a) \) = Value of taking action \( a \) in state \( s \).  
- \( \alpha \) = Learning rate.  
- \( r \) = Reward (profit/revenue from pricing decision).  
- \( \gamma \) = Discount factor.  
- \( \max Q(s', a') \) = Best Q-value for the next state \( s' \).  

### ğŸ“Œ **Flowchart of the RL Model**  
ğŸ”¹ **Input Data** (MRP, Sales, PED, Demand Trends)  
ğŸ”¹ **Agent Observes Price & PED**  
ğŸ”¹ **Agent Decides Pricing Action (Increase, Maintain, Decrease)**  
ğŸ”¹ **Revenue & Demand Feedback Collected**  
ğŸ”¹ **Q-Table Updated Based on Reward**  
ğŸ”¹ **Agent Learns & Optimizes Pricing**  

---

## âš™ï¸ **Hyperparameters & Training Process**  

| **Hyperparameter** | **Value Used** |
|-------------------|--------------|
| Learning Rate \( \alpha \) | 0.1 |
| Discount Factor \( \gamma \) | 0.9 |
| Exploration Rate \( \epsilon \) | Starts at 1.0, decays to 0.01 |
| Number of Episodes | 1000 |

### ğŸ“Š **Training Visualization**  

ğŸ“ˆ **1. Reward Convergence Over Time**  
ğŸ“Š **2. Exploration vs. Exploitation Trade-off**  

---

## ğŸ“Š **Experimental Results & Evaluation**  

### âœ… **Key Metrics Used**  

| **Metric** | **Description** |
|------------|----------------|
| **Revenue Improvement (%)** | Change in revenue due to RL pricing |
| **Profit Margin Impact (%)** | Impact on overall profitability |
| **PED Alignment (%)** | How well the RL model aligns with PED analysis |
| **Exploration vs. Exploitation Balance** | Evaluates whether the RL agent is too aggressive or conservative |

### âœ… **Evaluation Results**  

| **Item Type** | **Old Price** | **New Price (RL)** | **Revenue Change (%)** | **Profit Margin Change (%)** |
|--------------|--------------|---------------------|----------------------|---------------------------|
| Dairy       | 50           | 55                  | +8.5%                 | +6.3%                      |
| Snacks      | 30           | 27                  | -3.2%                 | +1.5%                      |
| Beverages   | 20           | 22                  | +5.1%                 | +4.8%                      |

### ğŸ“Š **Result Visualizations**  

ğŸ“‰ **1. Revenue Improvement (%) by Item Type**  
ğŸ“ˆ **2. Profit Margin Impact (%) by Item Type**  
ğŸ“Š **3. Price Elasticity Alignment (PED Impact Score Distribution)**  
ğŸ“Š **4. Exploration vs. Exploitation: Price Change Distribution**  

![output](https://github.com/user-attachments/assets/6e8722f6-63c6-4ecf-945f-f894623b83ad)
![Figure_1](https://github.com/user-attachments/assets/7d1c482f-d31f-4827-be89-fffcca9d862e)
![Figure_2](https://github.com/user-attachments/assets/de806cb1-498c-447e-934e-3955a3627b01)
![Figure_3](https://github.com/user-attachments/assets/026abde7-55ec-405e-85c2-1cb04b48be50)
![Figure_4](https://github.com/user-attachments/assets/e0e6c79b-40d4-4d64-a225-48648828d7b0)


---

## ğŸš€ **Conclusion & Future Work**  

### ğŸ“Œ **Conclusion**  
This project successfully demonstrates **Reinforcement Learning-based Dynamic Pricing**, integrating **PED insights** into pricing decisions. The **Q-Learning algorithm** optimally adjusts prices to **maximize revenue and profit**.  

### ğŸ”® **Future Enhancements**  
âœ”ï¸ **Testing on Real-World E-Commerce Data**  
âœ”ï¸ **Using Deep Q-Learning for Improved Decision-Making**  
âœ”ï¸ **Integrating Seasonal & Competitor Pricing Factors**  

---

## ğŸ“ **Project Structure**  

```
ğŸ“‚ dynamic-pricing-rl  
â”‚â”€â”€ ğŸ“œ RL_Pricing_Comparison.csv  # Comparison of RL vs. static pricing  
â”‚â”€â”€ ğŸ“œ PED_Results.csv  # Price Elasticity of Demand data  
â”‚â”€â”€ ğŸ“œ q_table.npy  # Trained Q-table  
â”‚â”€â”€ ğŸ“œ main.ipynb  # Jupyter notebook for training the RL model  
â”‚â”€â”€ ğŸ“œ evaluation.ipynb  # Notebook for analyzing and visualizing results  
â”‚â”€â”€ ğŸ“œ README.md  # This file  
```

---

## âš¡ **How to Run This Project**  

### **1ï¸âƒ£ Clone the Repository**  
```sh
git clone https://github.com/yourusername/dynamic-pricing-rl.git
cd dynamic-pricing-rl
```

### **2ï¸âƒ£ Install Dependencies**  
```sh
pip install numpy pandas matplotlib seaborn gym
```

### **3ï¸âƒ£ Train the RL Model**  
```sh
python main.py
```

### **4ï¸âƒ£ Evaluate Results**  
```sh
python evaluation.py
```

---

## ğŸ‘¨â€ğŸ’» **Connect with Me**  

ğŸ“§ **Email:** jasraj.shendge@example.com  
ğŸŒ **LinkedIn:** [Jasraj Shendge](https://www.linkedin.com/in/jasrajshendge/)  
ğŸ“‚ **GitHub:** [jasrajshendge](https://github.com/jasrajshendge)  

---

Let me know if you need further modifications! ğŸš€ğŸ”¥
